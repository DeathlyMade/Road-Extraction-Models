{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1634186,"sourceType":"datasetVersion","datasetId":966140}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:45:28.425390Z","iopub.execute_input":"2024-08-28T16:45:28.426036Z","iopub.status.idle":"2024-08-28T16:45:28.469875Z","shell.execute_reply.started":"2024-08-28T16:45:28.425972Z","shell.execute_reply":"2024-08-28T16:45:28.468625Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom data import trainGenerator, testGenerator, saveResult, testGenerator2\nimport keras.backend as K\nimport os, cv2\nimport numpy as np\nimport skimage.io as io\nimport skimage.transform as trans","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:45:28.582190Z","iopub.execute_input":"2024-08-28T16:45:28.582621Z","iopub.status.idle":"2024-08-28T16:45:43.771262Z","shell.execute_reply.started":"2024-08-28T16:45:28.582578Z","shell.execute_reply":"2024-08-28T16:45:43.769597Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, TensorBoard\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trainGenerator, testGenerator, saveResult, testGenerator2\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mK\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcv2\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"],"ename":"ModuleNotFoundError","evalue":"No module named 'data'","output_type":"error"}]},{"cell_type":"code","source":"# Code to crop images to specific size\n\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\ndef crop_image(src, save_path):\n    TEST_SET = os.listdir(src)\n    img_h = 256\n    img_w = 256\n    stride = img_h-40\n    for n in range(len(TEST_SET)):\n        image_name = TEST_SET[n]\n        path1 = image_name[0:-7]+'mask.png'  #rename mask\n        # load the image\n        # image = cv2.imread(os.path.join(src,image_name), cv2.IMREAD_UNCHANGED)\n        # image = cv2.imread(os.path.join(src,image_name))\n        print(os.path.join(src,image_name))\n        image = io.imread(os.path.join(src,image_name))\n        \n        print(image.shape)\n        h, w, _ = image.shape\n        # h, w = image.shape\n\n        num = 0;\n        #image = img_to_array(image)\n        # padding_img = (padding_img - np.min(padding_img)) / (np.max(padding_img) - np.min(padding_img))\n\n        print('[{}/{}], croping:{}'.format(n+1, len(TEST_SET), image_name))\n\n        #mask_whole = np.zeros((h, w, 1), dtype=np.uint8)\n        #temp = np.zeros((img_h, img_h), dtype=np.uint8)\n\n        for i in range(0, (h // stride)+1):\n            for j in range(0, (w // stride)+1):\n                h_begin = i * stride\n                w_begin = j * stride\n                \n                if h_begin + img_h > h:\n                    h_begin = h_begin - (h_begin + img_h - h)\n                \n                if w_begin + img_w > w:\n                    w_begin = w_begin - (w_begin + img_w - w)\n                \n                crop = image[h_begin:h_begin + img_h, w_begin:w_begin + img_w] \n                if num <= 9:\n                    #path1 = image_name[0:-4]+'0'+ str(num)+'.jpg'\n                    path1 = image_name[0:-4]+'0'+ str(num)+'.png'\n                else:\n                    #path1 = image_name[0:-4]+str(num)+'.jpg'\n                    path1 = image_name[0:-4]+str(num)+'.png'\n                \n                #io.imsave(save_path + path1, crop)\n                cv2.imwrite(save_path + path1, crop)\n                num = num + 1\n        print('Done!')","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:45:43.772146Z","iopub.status.idle":"2024-08-28T16:45:43.772599Z","shell.execute_reply.started":"2024-08-28T16:45:43.772377Z","shell.execute_reply":"2024-08-28T16:45:43.772400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Directory containing the PNG images\nsource_directory = '/kaggle/input/deepglobe-road-extraction-dataset/train'\n\n# Directory where PNG images will be moved\nsatelliteDir = \"/kaggle/working/satellite_images/\"\nmaskedDir = \"/kaggle/working/masked_images/\" \n\n# Create the subdirectory if it doesn't exist\nif not os.path.exists(satelliteDir):\n    os.makedirs(satelliteDir)\n    \nif not os.path.exists(maskedDir):\n    os.makedirs(maskedDir)\n\n# List all files in the directory\nall_files = os.listdir(source_directory)\n\n# Filter and move PNG files to the subdirectory\nfor file in all_files:\n    if file.endswith('.png'):\n        # Full path of the source file\n        source_path = os.path.join(source_directory, file)\n        \n        # Full path of the destination file\n        destination_path = os.path.join(maskedDir, file)\n        \n        # Move the file to the subdirectory\n        shutil.move(source_path, destination_path)\n    elif file.endswith('.jpg'):\n        # Full path of the source file\n        source_path = os.path.join(source_directory, file)\n        \n        # Full path of the destination file\n        destination_path = os.path.join(satelliteDir, file)\n        \n        # Move the file to the subdirectory\n        shutil.move(source_path, destination_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:45:43.774180Z","iopub.status.idle":"2024-08-28T16:45:43.774594Z","shell.execute_reply.started":"2024-08-28T16:45:43.774380Z","shell.execute_reply":"2024-08-28T16:45:43.774401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cropping Train Images\n\ncropsatDir = \"/kaggle/working/cropped_satellite_images/\"\ncropmaskDir = \"/kaggle/working/cropped_masked_images/\" \n\nif not os.path.exists(cropsatDir):\n    os.makedirs(cropsatDir)\n    \nif not os.path.exists(cropmaskDir):\n    os.makedirs(cropmaskDir)\n\ncrop_image(satelliteDir, cropsatDir)\ncrop_image(maskedDir, cropmaskDir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cropping Test images - To Be Done\n\n# satelliteDir = \"/kaggle/working/cropped_satellite_images/\"\n\n# directory = '/kaggle/input/deepglobe-road-extraction-dataset/test'\n# all_files = os.listdir(directory)\n\n# # Filter only PNG files\n# maskedImgs = [file for file in all_files if file.endswith('.png')]\n# satelImgs = [file for file in all_files if file.endswith('.jpg')]\n        \n# crop_image(satelImgs, satelliteDir)\n# crop_image(maskedImgs, maskedDir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet_model(input_shape=(572, 572, 3), num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T16:29:29.493999Z","iopub.execute_input":"2024-08-28T16:29:29.494440Z","iopub.status.idle":"2024-08-28T16:29:29.803330Z","shell.execute_reply.started":"2024-08-28T16:29:29.494396Z","shell.execute_reply":"2024-08-28T16:29:29.801986Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m572\u001b[39m, \u001b[38;5;241m572\u001b[39m, \u001b[38;5;241m3\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'unet_model' is not defined"],"ename":"NameError","evalue":"name 'unet_model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=3, verbose=0, mode='min', epsilon=1e-4, \n                              cooldown=0, min_lr=1e-6)\nvisual = TensorBoard(log_dir='./D_resunet1_log', histogram_freq=0, write_graph=True, write_images=True)\nearlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=0, mode='min')\n\ntrain_Gene = trainGenerator(2,'/kaggle/working/','cropped_satellite_images/','cropped_masked_images/',data_gen_args,save_to_dir = None)\n# to be fixed(train-val split)\n# val_Gene = trainGenerator(2,'data/membrane/IEEE_road/test/','sat_img_crops','masks_crops',data_gen_args)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = ModelCheckpoint('U-Net.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\nmodel.fit(train_Gene,steps_per_epoch=50,epochs=10,\n                    callbacks=[model_checkpoint, visual, reduce_lr, earlystop], \n                    validation_data=val_Gene, validation_steps=220)#step_per_epoch and validation_steps equals to number of samples divide batchsize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fileDir = \"data/membrane/IEEE_road/test/test_images/\"  #test images(1024*1024)\n#fileDir = \"data/membrane/train/f\"\npreDir = \"data/membrane/IEEE_road/test/sub_test/predict/\" #Dir of predict mask\n\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\ndef predict_z(src, predict_path):\n    TEST_SET = os.listdir(src)\n    model = D_resunet()\n    #model = res_unet1()\n    print('Loading Model weights...')\n    model.load_weights('D_resunet.hdf5')\n    print('completed!')\n    img_h = 256\n    img_w = 256\n    stride = img_h-16\n    for n in range(len(TEST_SET)):\n        path = TEST_SET[n]\n        path1 = path[0:-7]+'mask.png'  #rename mask\n        # load the image\n        image = io.imread(os.path.join(src,path))\n        h, w, _ = image.shape\n\n        image = image / 255.0\n        #image = img_to_array(image)\n        # padding_img = (padding_img - np.min(padding_img)) / (np.max(padding_img) - np.min(padding_img))\n\n        print('[{}/{}], predicting:{}'.format(n+1, len(TEST_SET), path))\n\n        mask_whole = np.zeros((h, w, 1), dtype=np.uint8)\n        #temp = np.zeros((img_h, img_h), dtype=np.uint8)\n\n        for i in range(0, (h // stride)+1):\n            for j in range(0, (w // stride)+1):\n                h_begin = i * stride\n                w_begin = j * stride\n                \n                if h_begin + img_h > h:\n                    h_begin = h_begin - (h_begin + img_h - h)\n                \n                if w_begin + img_w > w:\n                    w_begin = w_begin - (w_begin + img_w - w)\n                \n                crop = image[h_begin:h_begin + img_h, w_begin:w_begin + img_w, :3] #[****)\n                \n                ch, cw, _ = crop.shape\n\n                if ch != img_h or cw != img_h:\n                    print('invalid size!')\n                    print(i, j, h_begin, w_begin, ch, cw)\n                    break\n                \n                crop = np.expand_dims(crop, axis=0)\n                pred = model.predict(crop, verbose=2)\n                pred = pred.reshape((img_h, img_h, 1)).astype(np.float64)\n                #pred = np.argmax(pred, axis=2)\n                #print(pred.shape)\n                #pred = np.array(pred)\n                \n                pred[pred >= 0.5] = 1\n                pred[pred < 0.5] = 0\n                pred = pred * 255\n                '''\n                for a in range(img_h):\n                    for b in range(img_h):\n                        if pred[a, b] == 0.:\n                            temp[a, b, :] = [223, 223, 223]\n                        elif pred[a, b] == 1.:\n                            temp[a, b, :] = [255, 204, 163]\n                        else:\n                            print('Unknown type:', pred[a, b])\n                '''\n                mask_whole[h_begin:h_begin + img_h, w_begin:w_begin + img_w] \\\n                    = pred\n                # + mask_whole[i * stride:i * stride + image_size, j * stride:j * stride + image_size, :]\n        cv2.imwrite(predict_path + path1, mask_whole[0:h, 0:w])\n        #print('Done!')\n        \npredict_z(fileDir, preDir)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_block(inputs, num_filters): \n    # Convolution with 3x3 filter followed by ReLU activation \n    x = tf.keras.layers.Conv2D(num_filters, 3,padding = 'valid')(inputs) \n    x = tf.keras.layers.Activation('relu')(x) \n\n    # Convolution with 3x3 filter followed by ReLU activation \n    x = tf.keras.layers.Conv2D(num_filters, 3, padding = 'valid')(x) \n    x = tf.keras.layers.Activation('relu')(x) \n\n    # Max Pooling with 2x2 filter \n    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2), strides = 2)(x) \n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder_block(inputs, skip_features, num_filters): \n    # Upsampling with 2x2 filter \n    x = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides = 2, padding = 'valid')(inputs) \n      \n    # Copy and crop the skip features  \n    # to match the shape of the upsampled input \n    skip_features = tf.image.resize(skip_features, size = (x.shape[1], x.shape[2])) \n    x = tf.keras.layers.Concatenate()([x, skip_features]) \n      \n    # Convolution with 3x3 filter followed by ReLU activation \n    x = tf.keras.layers.Conv2D(num_filters, 3, padding = 'valid')(x) \n    x = tf.keras.layers.Activation('relu')(x) \n  \n    # Convolution with 3x3 filter followed by ReLU activation \n    x = tf.keras.layers.Conv2D(num_filters, 3, padding = 'valid')(x) \n    x = tf.keras.layers.Activation('relu')(x) \n      \n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code for Road Extraction using \n# Vanilla U-Net Architecture\nimport tensorflow as tf \n  \ndef unet_model(input_shape = (256, 256, 3), num_classes = 1): \n    inputs = tf.keras.layers.Input(input_shape) \n      \n    # Contracting Path \n    s1 = encoder_block(inputs, 64) \n    s2 = encoder_block(s1, 128) \n    s3 = encoder_block(s2, 256) \n    s4 = encoder_block(s3, 512) \n      \n    # Bottleneck \n    b1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(s4) \n    b1 = tf.keras.layers.Activation('relu')(b1) \n    b1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(b1) \n    b1 = tf.keras.layers.Activation('relu')(b1) \n      \n    # Expansive Path \n    s5 = decoder_block(b1, s4, 512) \n    s6 = decoder_block(s5, s3, 256) \n    s7 = decoder_block(s6, s2, 128) \n    s8 = decoder_block(s7, s1, 64) \n      \n    # Output \n    outputs = tf.keras.layers.Conv2D(num_classes, 1, padding = 'valid', activation = 'sigmoid')(s8) \n      \n    model = tf.keras.models.Model(inputs = inputs, outputs = outputs, name = 'U-Net') \n    return model ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}